{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP97/tzXziUyWA8vO128DcX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MIE524 - Assignment 1\n"],"metadata":{"id":"P3rGTK43YrNz"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"sk5Fl4bBY4k5"}},{"cell_type":"markdown","source":["Let's set up Spark on your Colab environment.  Run the cell below!"],"metadata":{"id":"KVBFUi_sY_Rl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mV-AdHT2Yk_4","executionInfo":{"status":"ok","timestamp":1685009568945,"user_tz":240,"elapsed":91910,"user":{"displayName":"Chang Liu","userId":"06149117597637958348"}},"outputId":"bb239726-146c-42c6-f2cc-295768e23553"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=56eec53fb07f311b79bc13e6336616581be135a50ac3d76c61fc8af82f2641c0\n","  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.0\n","The following additional packages will be installed:\n","  libxtst6 openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 3 newly installed, 0 to remove and 28 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 144 MB of additional disk space will be used.\n","Selecting previously unselected package libxtst6:amd64.\n","(Reading database ... 122532 files and directories currently installed.)\n","Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"]}],"source":["!pip install pyspark\n","!pip install -U -q PyDrive\n","!apt install openjdk-8-jdk-headless -qq\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""]},{"cell_type":"markdown","source":["Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n","\n","**Make sure to follow the interactive instructions.**"],"metadata":{"id":"cCNkNzbNZEOp"}},{"cell_type":"code","source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext\n","import pandas as pd\n","\n","# create the Spark Session\n","spark = SparkSession.builder.getOrCreate()\n","\n","# create the Spark Context\n","sc = spark.sparkContext"],"metadata":{"id":"LFZXyGgJZISe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Put all your imports, and path constants in the next cells."],"metadata":{"id":"3flXijoNxGW5"}},{"cell_type":"code","source":[],"metadata":{"id":"UZlFnHCuxPik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Q1 - Word Count in Spark"],"metadata":{"id":"zBzZCFTUZVIO"}},{"cell_type":"markdown","source":["### Load the dataset"],"metadata":{"id":"NG8u58Eh3onu"}},{"cell_type":"code","source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"metadata":{"id":"pSLA9G5UZBI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["id='1FNsvklbJa5ci-uSQbmX-lbpkkdEQl0iJ'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('plotsummaries.txt')"],"metadata":{"id":"v-98zo6ZZGTz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you executed the cells above, you should be able to see the file *plotsummaries.txt* under the \"Files\" tab on the left panel."],"metadata":{"id":"Zy7nM4ltZP3x"}},{"cell_type":"markdown","source":["### Write your function in the next cells"],"metadata":{"id":"APxI9MCs4Ovz"}},{"cell_type":"code","source":["def lower_str(word):\n","    \"\"\"\n","    INPUT:\n","        word: string\n","    OUTPUT:\n","        modified_wrod: string\n","\n","    NOTE: output the given word in lower case letters.\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","\n","def strip_punc(word):\n","    \"\"\"\n","    INPUT:\n","        word: string\n","    OUTPUT:\n","        modified_wrod: string\n","\n","    NOTE: output the given word with characters stripped.\n","    \"\"\"\n","\n","    # YOUR CODE HERE\n","\n","# You may have additional functions"],"metadata":{"id":"82TmJ8Ii3u4q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run your function in the next cells to output required content."],"metadata":{"id":"tcXHqu7q6IwZ"}},{"cell_type":"code","source":[],"metadata":{"id":"ZAIIrExX5_H-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PART 2 - Oxford Covid-19 Government Response Tracker"],"metadata":{"id":"pYACdWmz6MUT"}},{"cell_type":"markdown","source":["### Load the dataset"],"metadata":{"id":"7Cvzdbj37zyh"}},{"cell_type":"code","source":["id='1GuUEDg3ZZ9c-8k7ZwDq_Y9WcZlDT65S-'\n","downloaded = drive.CreateFile({'id': id})\n","downloaded.GetContentFile('OxCGRT_USA_latest.csv')"],"metadata":{"id":"rfUnVaKo6WaR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Q2 - Computing Index Score with Spark"],"metadata":{"id":"GFUIJwlD8KiM"}},{"cell_type":"code","source":["def clean_data(df):\n","    \"\"\"\n","    INPUT:\n","        df: spark dataframe\n","    OUTPUT:\n","        cleaned data: spark dataframe\n","\n","    NOTE: output the given word with characters stripped.\n","    \"\"\"\n","    # YOUR CODE HERE\n","\n","\n","def impute_data(df):\n","    \"\"\"\n","    INPUT:\n","        df: spark dataframe\n","    OUTPUT:\n","        imputed data: spark dataframe\n","\n","    NOTE: output the dataframe with nan values replaced with the minimal value of the given indicator.\n","    \"\"\"\n","    # YOUR CODE HERE\n","\n","def group_and_aggregate_data(df):\n","    \"\"\"\n","    INPUT:\n","        df: spark dataframe\n","    OUTPUT:\n","        groupe and aggregated data: spark dataframe\n","\n","    NOTE: output the dataframe with grouped (by month) and aggregated (based on the algorithm) data.\n","    \"\"\"\n","    # YOUR CODE HERE\n","\n","def compute_index_score(df):\n","    \"\"\"\n","    INPUT:\n","        df: spark dataframe\n","    OUTPUT:\n","        list of index scores per region and period: list\n","\n","    NOTE: output a list of computed scores per region and period based on the algorithm.\n","    \"\"\"\n","    # YOUR CODE HERE\n","\n","# You may have additional functions"],"metadata":{"id":"G4VuOGh78O4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# You may use below lists to get indicators and flags header\n","indicators = [\"C1M_School closing\",\n","\"C2M_Workplace closing\",\n","\"C3M_Cancel public events\",\n","\"C4M_Restrictions on gatherings\",\n","\"C5M_Close public transport\",\n","\"C6M_Stay at home requirements\",\n","\"C7M_Restrictions on internal movement\",\n","\"C8EV_International travel controls\",\n","\"E1_Income support\",\n","\"E2_Debt/contract relief\",\n","\"H1_Public information campaigns\",\n","\"H2_Testing policy\",\n","\"H3_Contact tracing\",\n","\"H6M_Facial Coverings\",\n","\"H7_Vaccination policy\",\n","\"H8M_Protection of elderly people\"]\n","\n","indicator_flags = [\"C1M_Flag\",\n","\"C2M_Flag\",\n","\"C3M_Flag\",\n","\"C4M_Flag\",\n","\"C5M_Flag\",\n","\"C6M_Flag\",\n","\"C7M_Flag\",\n","\"E1_Flag\",\n","\"H1_Flag\",\n","\"H6M_Flag\",\n","\"H7_Flag\",\n","\"H8M_Flag\"]"],"metadata":{"id":"aqQjGWmB7ykZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run your function in the next cells to output required content."],"metadata":{"id":"rEocWs4stsKs"}},{"cell_type":"code","source":[],"metadata":{"id":"OReazs5stsbh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Q3 - Association Rules"],"metadata":{"id":"7d6NcDhRtuTK"}},{"cell_type":"code","source":["def transform_to_items(df):\n","    \"\"\"\n","      INPUT:\n","          df: spark dataframe\n","      OUTPUT:\n","          list itemsets: list\n","\n","      NOTE: output a list itemsets from given dataframe.\n","      \"\"\"\n","      # YOUR CODE HERE"],"metadata":{"id":"m4okMWMT8ApT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apriori(items, min_sup, itemset_size):\n","    \"\"\"\n","    INPUT:\n","        items: list\n","        min_sup: the min support\n","    OUTPUT:\n","        list of frequent itemsets: list\n","\n","    NOTE: output a list of frequent itemsets.\n","    \"\"\"\n","    # YOUR CODE HERE\n","\n","# You may have additional functions"],"metadata":{"id":"jYTwc9Cgtw87"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run your function in the next cells to output required content."],"metadata":{"id":"YCZOK6SIxfXg"}},{"cell_type":"code","source":[],"metadata":{"id":"ccexb2wsxgxn"},"execution_count":null,"outputs":[]}]}